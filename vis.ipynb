{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "595197c0-50ac-4a78-a8ae-70e53c4e3456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "import webbrowser\n",
    "import os\n",
    "from transformer_lens import utils, HookedTransformer\n",
    "from datasets.arrow_dataset import Dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "import time\n",
    "\n",
    "# Library imports\n",
    "from sae_vis.utils_fns import get_device\n",
    "from sae_vis.model_fns import AutoEncoder, AutoEncoderConfig\n",
    "from sae_vis.data_storing_fns import SaeVisData\n",
    "from sae_vis.data_config_classes import SaeVisConfig\n",
    "# from sae_lens.training.sparse_autoencoder import SparseAutoencoder\n",
    "\n",
    "# Imports for displaying vis in Colab / notebook\n",
    "import webbrowser\n",
    "import http.server\n",
    "import socketserver\n",
    "import threading\n",
    "PORT = 8000\n",
    "\n",
    "device = get_device()\n",
    "torch.set_grad_enabled(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4cd52b42-5024-493f-9667-a59ce09f67e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_vis_inline(filename: str, height: int = 850):\n",
    "    '''\n",
    "    Displays the HTML files in Colab. Uses global `PORT` variable defined in prev cell, so that each\n",
    "    vis has a unique port without having to define a port within the function.\n",
    "    '''\n",
    "    webbrowser.open(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97c98065-0719-49fa-a555-53653522e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"/Users/joel/Downloads/sae.pth\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52ce0505-fb0c-4d17-8e41-75bee0db9f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 64])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict[\"encoder.weight\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39a666e2-81e5-4bdf-9c04-5aefda1d9afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict[\"encoder.bias\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7810befb-6e9e-431b-a540-6a721349e975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict[\"decoder.weight\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bf2db31-50b0-4863-bee3-7c5730395a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict[\"decoder.bias\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be426d84-1d9c-4c66-ad52-d1ec11205285",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state_dict = {\n",
    "    \"W_enc\": state_dict[\"encoder.weight\"].T,\n",
    "    \"b_enc\": state_dict[\"encoder.bias\"],\n",
    "    \"W_dec\": state_dict[\"decoder.weight\"].T,\n",
    "    \"b_dec\": state_dict[\"decoder.bias\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e850b81e-1e4b-4def-ab1f-ca4374042049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_enc: (64, 512)\n",
      "W_dec: (512, 64)\n",
      "b_enc: (512,)\n",
      "b_dec: (64,)\n"
     ]
    }
   ],
   "source": [
    "d_hidden, d_in = state_dict[\"encoder.weight\"].shape\n",
    "cfg = AutoEncoderConfig(d_in=d_in, d_hidden=d_hidden)\n",
    "encoder = AutoEncoder(cfg)\n",
    "encoder.load_state_dict(new_state_dict)\n",
    "\n",
    "for k, v in encoder.named_parameters():\n",
    "    print(f\"{k}: {tuple(v.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "269a1413-9340-4b62-b1d6-31990aff6388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joel/code/sae_expected_l0/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model roneneldan/TinyStories-1M into HookedTransformer\n",
      "Moving model to device:  mps\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"roneneldan/TinyStories-1M\")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e57260d-665c-463a-a587-a15caee3b180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3714797, 128])\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 128\n",
    "\n",
    "# Load in the data (it's a Dataset object)\n",
    "data = load_dataset(\"roneneldan/TinyStories\", split=\"train\")\n",
    "assert isinstance(data, Dataset)\n",
    "\n",
    "# Tokenize the data (using a utils function) and shuffle it\n",
    "tokenized_data = utils.tokenize_and_concatenate(data, model.tokenizer, max_length=SEQ_LEN) # type: ignore\n",
    "tokenized_data = tokenized_data.shuffle(42)\n",
    "\n",
    "# Get the tokens as a tensor\n",
    "all_tokens = tokenized_data[\"tokens\"]\n",
    "assert isinstance(all_tokens, torch.Tensor)\n",
    "\n",
    "print(all_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f456cfae-dd8f-4215-a8ae-dea9363e96fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1023f2c5-d632-4f81-8c09-5debb9d048b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cfg.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bfe4f96f-da74-4452-8b7c-5bd5d369a754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.W_enc.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b1f1dcb-4ea2-4fad-8520-b44cae5f16b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(d_in=64, dict_mult=8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e683bba-c087-44a5-a249-2f2e40613656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the hook point you're using, and the features you're analyzing\n",
    "sae_vis_config = SaeVisConfig(\n",
    "    hook_point = \"blocks.4.hook_resid_post\",\n",
    "    features = range(64),\n",
    "    verbose = True,\n",
    ")\n",
    "\n",
    "# Gather the feature data\n",
    "sae_vis_data = SaeVisData.create(\n",
    "    encoder = encoder,\n",
    "    # encoder_B = encoder_B,\n",
    "    model = model,\n",
    "    tokens = all_tokens[:2048],\n",
    "    cfg = sae_vis_config,\n",
    ")\n",
    "\n",
    "# Save as HTML file & display vis\n",
    "filename = \"_feature_vis_demo.html\"\n",
    "sae_vis_data.save_feature_centric_vis(filename, feature_idx=8)\n",
    "\n",
    "display_vis_inline(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
